{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN_qlgifSe-r"
      },
      "source": [
        "# 1.Gather and Label Images   (by using labelme tool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCN626ciTt3M"
      },
      "source": [
        "#2.Upload Dataset and Prepare Dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_v4kqsrhxHj"
      },
      "outputs": [],
      "source": [
        "#Importing dataset from Google Drive in Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "le2jyg43tY_k"
      },
      "outputs": [],
      "source": [
        "#to unzip a folder\n",
        "!unzip -q /content/drive/MyDrive/Blind_Guide/currency_detector_data/all_data_3.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVfx8Gq7V8nP"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import albumentations as alb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import random\n",
        "import sys\n",
        "import uuid\n",
        "import tensorflow as tf\n",
        "import IPython.display as display\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBw_74tqVzyh"
      },
      "outputs": [],
      "source": [
        "shortcut=True # We used shortcut names to classes, if you didn't, make shortcut = False\n",
        "LABELS={0.25:'25_piasters',0.50:'50_piasters',\n",
        "            1:'1_pound',5:'5_pounds',10:'10_pounds',\n",
        "            20:'20_pounds',50:'50_pounds',\n",
        "            100:'100_pounds',200:'200_pounds'}\n",
        "def modify_on_json_files(jsonPath):\n",
        "    ''' modify files to make it suitable for SSD model (x_min,y_min),(x_max,y_max) '''\n",
        "    print('modify on json files function is running ....')\n",
        "    for file in os.listdir(os.path.join(jsonPath)):\n",
        "        j=open(os.path.join(jsonPath,file))\n",
        "        df=json.load(j)#load json file\n",
        "        name=file.split('.')[0]\n",
        "        dic={'object':[]}\n",
        "        dic['image']=f'{name}.jpg'\n",
        "        try:\n",
        "            for i in range(len(df['shapes'])):\n",
        "                w,h=df['imageWidth'],df['imageHeight']\n",
        "                x1=max(0,min(df['shapes'][i]['points'][0][0],df['shapes'][i]['points'][1][0])/w)*320\n",
        "                y1=max(0,min(df['shapes'][i]['points'][0][1],df['shapes'][i]['points'][1][1])/h)*320\n",
        "                x2=min(1,max(df['shapes'][i]['points'][0][0],df['shapes'][i]['points'][1][0])/w)*320\n",
        "                y2=min(1,max(df['shapes'][i]['points'][0][1],df['shapes'][i]['points'][1][1])/h)*320\n",
        "                obj={}\n",
        "                obj['bbox']=[x1,y1,x2,y2]\n",
        "                if shortcut:\n",
        "                    obj['class']=LABELS[float(df['shapes'][i]['label'])]\n",
        "                else:\n",
        "                    obj['class']=df['shapes'][i]['label']\n",
        "                dic['object'].append(obj)\n",
        "            json_object=json.dumps(dic)\n",
        "            with open(os.path.join(jsonPath,file), \"w\") as outfile:\n",
        "                outfile.write(json_object)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "    print(f'Successfully modified json files in path : \\'{jsonPath}\\'')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUjZWP5vYC8m"
      },
      "outputs": [],
      "source": [
        "def resizeImages(path,shape):\n",
        "    '''resize image to (320,320)'''\n",
        "    print('Resize images function is running....')\n",
        "    for image in os.listdir(path):\n",
        "        img=cv2.imread(os.path.join(path,image))\n",
        "        if img is not None and img.size != 0:\n",
        "            resizedImage=cv2.resize(img,shape, interpolation = cv2.INTER_AREA)\n",
        "            cv2.imwrite(os.path.join(path,f'{image.split(\".\")[0]}.jpg'),resizedImage)\n",
        "    print(f'Successfully resized images in path : \\'{path}\\'')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRRE8s7jYLG1"
      },
      "outputs": [],
      "source": [
        "def spilt(images_path,labels_path,ratio):\n",
        "    '''split data into train, val, and test folders'''\n",
        "    print('split function is running ....')\n",
        "    for folder in ['train','val']:\n",
        "        os.makedirs(os.path.join('data',folder,'images'))\n",
        "        os.makedirs(os.path.join('data',folder,'labels'))\n",
        "    train_path=os.path.join('data','train')\n",
        "    val_path=os.path.join('data','val')\n",
        "    images_list=os.listdir(images_path)\n",
        "    random.seed(10)\n",
        "    random.shuffle(images_list)\n",
        "    train_size=int(len(images_list)*ratio)\n",
        "    train_list=images_list[:train_size]\n",
        "    val_list=images_list[train_size:]\n",
        "    print(f'Train data size : {len(train_list)}\\nValidation data size : {len(val_list)}')\n",
        "    for i in train_list:\n",
        "        shutil.move(os.path.join(images_path,i),\n",
        "                    os.path.join(train_path,'images',i))\n",
        "        shutil.move(os.path.join(labels_path,f'{i.split(\".\")[0]}.json'),\n",
        "                    os.path.join(train_path,'labels',f'{i.split(\".\")[0]}.json'))\n",
        "    for i in val_list:\n",
        "        shutil.move(os.path.join(images_path,i),\n",
        "                    os.path.join(val_path,'images',i))\n",
        "        shutil.move(os.path.join(labels_path,f'{i.split(\".\")[0]}.json'),\n",
        "                    os.path.join(val_path,'labels',f'{i.split(\".\")[0]}.json'))\n",
        "    print('Successfully split data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LtzWJ7ZW3Mo"
      },
      "outputs": [],
      "source": [
        "def augmentation(crop_size,images_path,labels_path,augmentation_num,augmented_images_path,augmented_labels_path,image_shape):\n",
        "    print('Augmentation function is running ....')\n",
        "    aumentor=alb.Compose([\n",
        "        alb.RandomCrop(*crop_size),\n",
        "        alb.HorizontalFlip(p=0.5),\n",
        "        alb.RandomBrightnessContrast(p=0.2),\n",
        "        alb.RandomGamma(p=0.2),\n",
        "        alb.RGBShift(p=0.2),\n",
        "        alb.VerticalFlip(p=0.5)],\n",
        "        bbox_params=alb.BboxParams(format='albumentations',label_fields=['class_labels']))\n",
        "    if not os.path.exists(augmented_images_path):\n",
        "        os.makedirs(augmented_images_path)\n",
        "    if not os.path.exists(augmented_labels_path):\n",
        "        os.makedirs(augmented_labels_path)\n",
        "    for image in os.listdir(images_path):\n",
        "        img=cv2.imread(os.path.join(images_path,image))\n",
        "        label_path=os.path.join(labels_path,f'{image.split(\".\")[0]}.json')\n",
        "        with open(label_path,'r') as f:\n",
        "            label=json.load(f)\n",
        "        l,c=[],[]\n",
        "        for i in range(len(label['object'])):\n",
        "            coords=[0,0,0,0]\n",
        "            coords[0]=label['object'][i]['bbox'][0]/image_shape[0]\n",
        "            coords[1]=label['object'][i]['bbox'][1]/image_shape[1]\n",
        "            coords[2]=label['object'][i]['bbox'][2]/image_shape[0]\n",
        "            coords[3]=label['object'][i]['bbox'][3]/image_shape[1]\n",
        "            Label=label['object'][i]['class']\n",
        "            l.append(Label)\n",
        "            c.append(coords)\n",
        "        try:\n",
        "            for x in range(augmentation_num):\n",
        "                name=str(uuid.uuid4())\n",
        "                name=name.replace('-','')\n",
        "                augmented=aumentor(image=img,bboxes=c,class_labels=l)\n",
        "                resized_image=cv2.resize(augmented['image'],image_shape, interpolation = cv2.INTER_AREA)\n",
        "                cv2.imwrite(os.path.join(augmented_images_path,f'{name}.jpg'),resized_image)\n",
        "                dic={'object':[]}\n",
        "                dic['image']=f'{name}.jpg'\n",
        "                for i in range(len(label['object'])):\n",
        "                    annotation={}\n",
        "                    annotation['bbox']=''\n",
        "                    annotation['class']=''\n",
        "                    if len(augmented['bboxes'])==0:\n",
        "                        annotation['bbox']=[0,0,0,0]\n",
        "                        annotation['class']='EOF'\n",
        "                    else:\n",
        "                        annotation['class']=augmented['class_labels'][i]\n",
        "                        annotation['bbox']=[int(p*320) for p in augmented['bboxes'][i]]\n",
        "                    dic['object'].append( annotation)\n",
        "                with open (os.path.join(augmented_labels_path,f'{name}.json'),'w') as f:\n",
        "                    json.dump(dic,f)\n",
        "        except Exception as e:\n",
        "            print(e,'---> file path:',os.path.join(images_path,image))\n",
        "    print(f'Successfully augmented data in path  : \\'{augmented_images_path}\\' and \\'{augmented_labels_path}\\'')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIPj0QCbYnnb"
      },
      "outputs": [],
      "source": [
        "#convert json files to csv file\n",
        "def json_to_csv(label_path,csv_path):\n",
        "    print('convert json files to csv file function is running ....')\n",
        "    json_list=[]\n",
        "    for file in os.listdir(os.path.join(label_path)):\n",
        "        x=open(os.path.join(label_path,file))\n",
        "        data=json.load(x)\n",
        "        for i in range(len(data['object'])):\n",
        "            value = (data['image'],320,320,data['object'][i]['class'],\n",
        "                     data['object'][i]['bbox'][0],\n",
        "                     data['object'][i]['bbox'][1],\n",
        "                     data['object'][i]['bbox'][2],\n",
        "                     data['object'][i]['bbox'][3])\n",
        "            json_list.append(value)\n",
        "\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    json_df = pd.DataFrame(json_list, columns=column_name)\n",
        "    json_df.to_csv(csv_path, index=None)\n",
        "    print(f'Successfully converted json to csv. in path {csv_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWJ5oodNY01s"
      },
      "outputs": [],
      "source": [
        "color={'25_piasters':(0,0,128),'50_piasters':(0,128,128),\n",
        "           '1_pound':(128,0,128),'5_pounds':(0,128,0),\n",
        "           '10_pounds':(128,128,0),'20_pounds':(128,0,0),\n",
        "           '50_pounds':(47,79,79),'100_pounds':(153,50,204),\n",
        "       '200_pounds':(199,21,133),'EOF':(255,255,255)}\n",
        "def view_data(images_path,labels_path,num_test_images,image_shape):\n",
        "    images=os.listdir(images_path)\n",
        "    random.seed(10)\n",
        "    images_to_test = random.sample(images, num_test_images)\n",
        "\n",
        "    for image_path in images_to_test:\n",
        "        with open(os.path.join(labels_path,f'{image_path.split(\".\")[0]}.json'),'r') as f:\n",
        "            label=json.load(f)\n",
        "        image=cv2.imread(os.path.join(images_path,image_path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        for i in range(len(label['object'])):\n",
        "            xmin=int(label['object'][i]['bbox'][0])\n",
        "            ymin=int(label['object'][i]['bbox'][1])\n",
        "            xmax=int(label['object'][i]['bbox'][2])\n",
        "            ymax=int(label['object'][i]['bbox'][3])\n",
        "\n",
        "            cv2.rectangle(image,(xmin,ymin), (xmax,ymax),color[label['object'][i]['class']], 1)\n",
        "            p1,p2=(xmin,ymin),(xmax,ymax)\n",
        "            lw = max(round(sum(image.shape) / 2 * 0.003), 2)\n",
        "            tf = max(lw - 1, 1)\n",
        "            Label=label['object'][i]['class']\n",
        "            w, h = cv2.getTextSize(Label, 0, fontScale=lw / 3, thickness=tf)[0]  # text width, height\n",
        "            outside = p1[1] - h >= 3\n",
        "            p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
        "            cv2.rectangle(image, p1, p2, color[label['object'][i]['class']], -1, cv2.LINE_AA)  # filled\n",
        "            cv2.putText(image,Label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),0,lw / 3,(255, 255, 255),thickness=tf,lineType=cv2.LINE_AA)\n",
        "        plt.figure(figsize=(8,8))\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydbpWZtJY1zj"
      },
      "outputs": [],
      "source": [
        "def Prepare_Dataset(images_path,labels_path,image_shape,augmentation_num=0,ratio=0.8):\n",
        "    modify_on_json_files(labels_path)\n",
        "    resizeImages(images_path,image_shape)\n",
        "    spilt(images_path,\n",
        "          labels_path,\n",
        "          ratio)\n",
        "    data='data'\n",
        "    if augmentation_num:\n",
        "      data='augmented_data'\n",
        "      for folder in ['train','val']:\n",
        "          Images_path=os.path.join('data',folder,'images')\n",
        "          Labels_path=os.path.join('data',folder,'labels')\n",
        "          augmented_images_path=os.path.join('augmented_data',folder,'images')\n",
        "          augmented_labels_path=os.path.join('augmented_data',folder,'labels')\n",
        "          crop_size=(300,300)\n",
        "          augmentation(crop_size,\n",
        "                      Images_path,\n",
        "                      Labels_path,\n",
        "                      augmentation_num,\n",
        "                      augmented_images_path,\n",
        "                      augmented_labels_path,\n",
        "                      image_shape)\n",
        "\n",
        "\n",
        "\n",
        "    os.makedirs('csv')\n",
        "    for folder in ['train','val']:\n",
        "        print(os.path.join(data,folder,'labels'))\n",
        "        Labels_path=os.path.join(data,folder,'labels')\n",
        "        csv_path=os.path.join('csv',f'{folder}.csv')\n",
        "        json_to_csv(Labels_path,csv_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21f7CHzSY8Sk"
      },
      "outputs": [],
      "source": [
        "images_path=r'/content/all_data_3/images'\n",
        "labels_path=r'/content/all_data_3/labels'\n",
        "image_shape=(320,320)\n",
        "augmentation_num=2\n",
        "Prepare_Dataset(images_path,labels_path,image_shape,augmentation_num,0.8)\n",
        "\n",
        "data ='augmented_data' if augmentation_num else'data'\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "05E7ivR7Y-IE"
      },
      "outputs": [],
      "source": [
        "for folder in ['train','val']:\n",
        "        Images_path=os.path.join('/content',data,folder,'images')\n",
        "        Labels_path=os.path.join('/content',data,folder,'labels')\n",
        "        image_shape=(320,320)\n",
        "        view_data(Images_path,Labels_path,10,image_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N5yxaWe5ZC7k"
      },
      "outputs": [],
      "source": [
        "train=pd.read_csv(r'/content/csv/train.csv')\n",
        "train.drop(train.index[(train[\"class\"] == \"0\")],axis=0,inplace=True)\n",
        "train.to_csv(r'/content/csv/train.csv', index=None)\n",
        "train['class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1iBAsoeEOuPz"
      },
      "outputs": [],
      "source": [
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5UQKNIPvZGjs"
      },
      "outputs": [],
      "source": [
        "val=pd.read_csv(r'/content/csv/val.csv')\n",
        "val.drop(val.index[(val[\"class\"] == \"0\")],axis=0,inplace=True)\n",
        "val.to_csv(r'/content/csv/val.csv', index=None)\n",
        "val['class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LfSOT-x_O526"
      },
      "outputs": [],
      "source": [
        "val.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oTD9A5VUXrt"
      },
      "source": [
        "#3.Install TensorFlow Object Detection Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zx1_VGGxmWSB"
      },
      "outputs": [],
      "source": [
        "# Clone the tensorflow models repository from GitHub\n",
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VxqZnkJmmaxx"
      },
      "outputs": [],
      "source": [
        "# Copy setup files into models/research folder\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "#cp object_detection/packages/tf2/setup.py ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JCBCgvohmc4B"
      },
      "outputs": [],
      "source": [
        "# Modify setup.py file to install the tf-models-official repository targeted at TF v2.8.0\n",
        "import re\n",
        "with open('/content/models/research/object_detection/packages/tf2/setup.py') as f:\n",
        "    s = f.read()\n",
        "\n",
        "with open('/content/models/research/setup.py', 'w') as f:\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('tf-models-official>=2.5.1',\n",
        "               'tf-models-official==2.8.0', s)\n",
        "    f.write(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg1i4CdMmfFY"
      },
      "outputs": [],
      "source": [
        "# Install the Object Detection API\n",
        "!pip install /content/models/research/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qNhLZb0VZs9"
      },
      "source": [
        "#4.Create TFRecords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Y9J21JnZWCL"
      },
      "outputs": [],
      "source": [
        "### This creates a a \"labelmap.txt\" file with a list of classes the object detection model will detect.\n",
        "%%bash\n",
        "cat <<EOF >> /content/currency.txt\n",
        "25_piasters\n",
        "50_piasters\n",
        "1_pound\n",
        "5_pounds\n",
        "10_pounds\n",
        "20_pounds\n",
        "50_pounds\n",
        "100_pounds\n",
        "200_pounds\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9AGTDYrZcVR"
      },
      "outputs": [],
      "source": [
        "! wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_tfrecord.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ou0-bvJZj-T"
      },
      "outputs": [],
      "source": [
        "if augmentation_num:\n",
        "  !python create_tfrecord.py --csv_input=/content/csv/train.csv --labelmap=/content/currency.txt --image_dir=/content/augmented_data/train/images --output_path=train.tfrecord\n",
        "  !python create_tfrecord.py --csv_input=/content/csv/val.csv --labelmap=/content/currency.txt --image_dir=/content/augmented_data/val/images --output_path=val.tfrecord\n",
        "else:\n",
        "   !python create_tfrecord.py --csv_input=/content/csv/train.csv --labelmap=/content/currency.txt --image_dir=/content/data/train/images --output_path=train.tfrecord\n",
        "   !python create_tfrecord.py --csv_input=/content/csv/val.csv --labelmap=/content/currency.txt --image_dir=/content/data/val/images --output_path=val.tfrecord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxGQ3rMqujIv"
      },
      "outputs": [],
      "source": [
        "train_record_fname = '/content/train.tfrecord'\n",
        "val_record_fname = '/content/val.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/labelmap.pbtxt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C85o-HHtn1I_"
      },
      "source": [
        "#5.Set Up Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFLoFGkXn9a2"
      },
      "outputs": [],
      "source": [
        "# Change the chosen_model variable to deploy different models available in the TF2 object detection zoo\n",
        "chosen_model = 'ssd-mobilenet-v2-fpnlite-320'\n",
        "model_name = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "pretrained_checkpoint = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "base_pipeline_file = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6miNQNICoDsA"
      },
      "outputs": [],
      "source": [
        "# Create \"mymodel\" folder for holding pre-trained weights and configuration files\n",
        "%mkdir /content/models/mymodel/\n",
        "%cd /content/models/mymodel/\n",
        "\n",
        "# Download pre-trained model weights\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Download training configuration file for model\n",
        "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
        "!wget {download_config}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aFiSek-oFOW"
      },
      "outputs": [],
      "source": [
        "# Set training parameters for the model\n",
        "num_steps = 35000\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xoavkMSoJ0m"
      },
      "outputs": [],
      "source": [
        "# Set file locations and get number of classes for config file\n",
        "pipeline_fname = '/content/models/mymodel/' + base_pipeline_file\n",
        "fine_tune_checkpoint = '/content/models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "print('Total classes:', num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fxmi_dQ8oMm3"
      },
      "outputs": [],
      "source": [
        "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "import re\n",
        "\n",
        "%cd /content/models/mymodel\n",
        "print('writing custom configuration file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "\n",
        "    # Set tfrecord files for train and test datasets\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
        "\n",
        "    # Set label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set batch_size\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    # Set number of classes num_classes\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "\n",
        "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "\n",
        "    # If using ssd-mobilenet-v2, reduce learning rate (because it's too high in the default config file)\n",
        "    if chosen_model == 'ssd-mobilenet-v2':\n",
        "      s = re.sub('learning_rate_base: .8',\n",
        "                 'learning_rate_base: .08', s)\n",
        "\n",
        "      s = re.sub('warmup_learning_rate: 0.13333',\n",
        "                 'warmup_learning_rate: .026666', s)\n",
        "    f.write(s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPXvzgyGoOum"
      },
      "outputs": [],
      "source": [
        "# (Optional) Display the custom configuration file's contents\n",
        "!cat /content/models/mymodel/pipeline_file.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xP_PmouoQ-g"
      },
      "outputs": [],
      "source": [
        "# Set the path to the custom config file and the directory to store training checkpoints in\n",
        "pipeline_file = '/content/models/mymodel/pipeline_file.config'\n",
        "model_dir = '/content/training/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfQeui_GWUmi"
      },
      "source": [
        "#6.Train Custom TFLite Detection Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-RvHdlMv8qx"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LIokOs8owGnj"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Run training!\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdmqrkwJYAtD"
      },
      "source": [
        "#7.Convert Model to TensorFlow Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gWYmMBMRrP0m"
      },
      "outputs": [],
      "source": [
        "# Make a directory to store the trained TFLite model\n",
        "!mkdir /content/custom_model_lite\n",
        "output_directory = '/content/custom_model_lite'\n",
        "\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = '/content/training'\n",
        "\n",
        "!python /content/models/research/object_detection/export_tflite_graph_tf2.py \\\n",
        "    --trained_checkpoint_dir {last_model_path} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_file}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "178Tj11zokaN"
      },
      "outputs": [],
      "source": [
        "# Convert exported graph file into TFLite model file\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/custom_model_lite/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('/content/custom_model_lite/detect.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYm8VQtIYidh"
      },
      "source": [
        "#8.Test TensorFlow Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iNlAa-Bk35QJ"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/Blind_Guide/currency_detector_data/test.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lu2DQnTDEVLp"
      },
      "outputs": [],
      "source": [
        "# Script to run custom TFLite model on test images to detect objects\n",
        "# Source: https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/TFLite_detection_image.py\n",
        "\n",
        "# Import packages\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "import importlib.util\n",
        "from tensorflow.lite.python.interpreter import Interpreter\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "color={'25_piasters':(0,0,128),'50_piasters':(0,128,128),\n",
        "           '1_pound':(128,0,128),'5_pounds':(0,128,0),\n",
        "           '10_pounds':(128,128,0),'20_pounds':(128,0,0),\n",
        "           '50_pounds':(47,79,79),'100_pounds':(153,50,204),\n",
        "       '200_pounds':(199,21,133),'EOF':(255,255,255)}\n",
        "def tflite_detect_images(modelpath, imgpath, lblpath, min_conf=0.5, num_test_images=60, savepath='/content/results'):\n",
        "\n",
        "  # Grab filenames of all images in test folder\n",
        "  images = glob.glob(imgpath + '/*.jpg') + glob.glob(imgpath + '/*.JPG') + glob.glob(imgpath + '/*.png') + glob.glob(imgpath + '/*.bmp')+ glob.glob(imgpath + '/*.jpeg')\n",
        "\n",
        "  # Load the label map into memory\n",
        "  with open(lblpath, 'r') as f:\n",
        "      labels = [line.strip() for line in f.readlines()]\n",
        "\n",
        "  # Load the Tensorflow Lite model into memory\n",
        "  interpreter = Interpreter(model_path=modelpath)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  # Get model details\n",
        "  input_details = interpreter.get_input_details()\n",
        "  output_details = interpreter.get_output_details()\n",
        "  height = input_details[0]['shape'][1]\n",
        "  width = input_details[0]['shape'][2]\n",
        "\n",
        "  float_input = (input_details[0]['dtype'] == np.float32)\n",
        "\n",
        "  input_mean = 127.5\n",
        "  input_std = 127.5\n",
        "\n",
        "  # Randomly select test images\n",
        "  images_to_test = random.sample(images, num_test_images)\n",
        "\n",
        "  # Loop over every image and perform detection\n",
        "  for image_path in images_to_test:\n",
        "\n",
        "      # Load image and resize to expected shape [1xHxWx3]\n",
        "      image = cv2.imread(image_path)\n",
        "      image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      imH, imW, _ = image.shape\n",
        "      image_resized = cv2.resize(image_rgb, (width, height))\n",
        "      input_data = np.expand_dims(image_resized, axis=0)\n",
        "\n",
        "      # Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n",
        "      if float_input:\n",
        "          input_data = (np.float32(input_data) - input_mean) / input_std\n",
        "\n",
        "      # Perform the actual detection by running the model with the image as input\n",
        "      interpreter.set_tensor(input_details[0]['index'],input_data)\n",
        "      interpreter.invoke()\n",
        "\n",
        "      # Retrieve detection results\n",
        "      boxes = interpreter.get_tensor(output_details[1]['index'])[0] # Bounding box coordinates of detected objects\n",
        "      classes = interpreter.get_tensor(output_details[3]['index'])[0] # Class index of detected objects\n",
        "      scores = interpreter.get_tensor(output_details[0]['index'])[0] # Confidence of detected objects\n",
        "\n",
        "      detections = []\n",
        "\n",
        "      # Loop over all detections and draw detection box if confidence is above minimum threshold\n",
        "      for i in range(len(scores)):\n",
        "          if ((scores[i] > min_conf) and (scores[i] <= 1.0)):\n",
        "\n",
        "              # Get bounding box coordinates and draw box\n",
        "              # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()\n",
        "              ymin = int(max(1,(boxes[i][0] * imH)))\n",
        "              xmin = int(max(1,(boxes[i][1] * imW)))\n",
        "              ymax = int(min(imH,(boxes[i][2] * imH)))\n",
        "              xmax = int(min(imW,(boxes[i][3] * imW)))\n",
        "              p1,p2=(xmin,ymin),(xmax,ymax)\n",
        "              cv2.rectangle(image, p1, p2, color[labels[int(classes[i])]], 2)\n",
        "              # Draw label\n",
        "              lw = max(round(sum(image.shape) / 2 * 0.003), 2)\n",
        "              tf = max(lw - 1, 1)\n",
        "              object_name = labels[int(classes[i])] # Look up object name from \"labels\" array using class index\n",
        "              label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'\n",
        "              w, h = cv2.getTextSize(label, 0, fontScale=lw / 3, thickness=tf)[0]  # text width, height\n",
        "              outside = p1[1] - h >= 3\n",
        "              p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
        "              cv2.rectangle(image, p1, p2, color[labels[int(classes[i])]], -1, cv2.LINE_AA)\n",
        "              cv2.putText(image,label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),0,lw / 3,(255, 255, 255),thickness=tf,lineType=cv2.LINE_AA)\n",
        "              detections.append([object_name, scores[i], xmin, ymin, xmax, ymax])\n",
        "\n",
        "\n",
        "      image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "      plt.figure(figsize=(12,16))\n",
        "      plt.imshow(image)\n",
        "      plt.show()\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kyzOELecoy6W"
      },
      "outputs": [],
      "source": [
        "# Set up variables for running user's model\n",
        "PATH_TO_IMAGES='/content/test'   # Path to test images folder\n",
        "PATH_TO_MODEL='/content/custom_model_lite/detect.tflite'   # Path to .tflite model file\n",
        "PATH_TO_LABELS='/content/currency.txt'   # Path to labelmap.txt file\n",
        "min_conf_threshold=0.5   # Confidence threshold (try changing this to 0.01 if you don't see any detection results)\n",
        "images_to_test = 10   # Number of images to run detection on\n",
        "# Run inferencing function!\n",
        "tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0oDzvbTY2QI"
      },
      "source": [
        "#9.Download TensorFlow Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OMjdfDMUqfDA"
      },
      "outputs": [],
      "source": [
        "# Move labelmap and pipeline config files into TFLite model folder and zip it up\n",
        "!cp /content/currency.txt /content/custom_model_lite\n",
        "!cp /content/labelmap.pbtxt /content/custom_model_lite\n",
        "!cp /content/models/mymodel/pipeline_file.config /content/custom_model_lite\n",
        "%cd /content\n",
        "!zip -r custom_model_lite.zip custom_model_lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Bw8BHApZeKDf"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/custom_model_lite.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2RLpK1VT4ULt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "OCN626ciTt3M",
        "3oTD9A5VUXrt",
        "5qNhLZb0VZs9",
        "C85o-HHtn1I_"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}